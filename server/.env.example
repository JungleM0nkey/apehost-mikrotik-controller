# Server Configuration
PORT=3000
NODE_ENV=development

# CORS Configuration
CORS_ORIGIN=http://localhost:5173

# MikroTik Router Configuration
MIKROTIK_HOST=192.168.88.1
MIKROTIK_PORT=8728
MIKROTIK_USERNAME=admin
MIKROTIK_PASSWORD="your_password_here"  # Use quotes if password contains # or other special chars
MIKROTIK_TIMEOUT=10000

# WebSocket Configuration (future)
WS_PORT=3001

# AI Provider Configuration
# Choose your AI provider: claude, lmstudio, or cloudflare
LLM_PROVIDER=claude

# Claude AI (Anthropic) - Premium quality, high cost
ANTHROPIC_API_KEY=sk-ant-your-api-key-here
CLAUDE_MODEL=claude-3-5-sonnet-20241022

# LM Studio - Local inference
LMSTUDIO_ENDPOINT=http://192.168.100.200:1234/v1
LMSTUDIO_MODEL=ibm/granite-4-h-tiny
# Context window for the loaded model (LM Studio API doesn't expose this)
# Set this to match your model's context window in LM Studio
LMSTUDIO_CONTEXT_WINDOW=70752

# Cloudflare Workers AI - 93% cheaper than Claude, with function calling
CLOUDFLARE_ACCOUNT_ID=your_cloudflare_account_id
CLOUDFLARE_API_TOKEN=your_cloudflare_api_token
CLOUDFLARE_AI_MODEL=@cf/meta/llama-4-scout-17b-16e-instruct
# Optional: AI Gateway for caching and analytics
# CLOUDFLARE_AI_GATEWAY=my-gateway-name
